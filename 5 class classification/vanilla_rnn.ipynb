{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# imports\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import glob\r\n",
    "import cv2\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import random\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from tensorflow.contrib import rnn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class_names = [\"EMCI\",\"LMCI\",\"MCI\",\"AD\",\"CN\"]\r\n",
    "# class_index=[0,1,2,3,4]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path=r\"G:\\dataset\\Alzheimers-ADNI\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "'''reading the images'''\r\n",
    "data=dict()\r\n",
    "# trainData=[]\r\n",
    "# trainDataLables=[]\r\n",
    "coo_matrix=[]\r\n",
    "for name in class_names:\r\n",
    "    images = [cv2.imread(file,cv2.COLOR_BGR2GRAY) for file in glob.glob(path+\"\\\\train\\\\\"+name+r'\\*.jpg')]\r\n",
    "    coo_matrix.append({name:len(images)})\r\n",
    "    temp=[]\r\n",
    "    for i in images:\r\n",
    "        i=cv2.resize(i,(256, 256))\r\n",
    "        temp.append(np.asarray(i).reshape(256, 256))\r\n",
    "    data[name]=temp\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "'''balancing imbalanced data'''\r\n",
    "print('before')\r\n",
    "print(coo_matrix)\r\n",
    "max_count=0\r\n",
    "for name in class_names:\r\n",
    "    if len(data[name])>max_count:\r\n",
    "        max_count=len(data[name])\r\n",
    "print(max_count)\r\n",
    "\r\n",
    "for name in class_names:\r\n",
    "    n=len(data[name])\r\n",
    "    for t in range(n,max_count):\r\n",
    "        data[name].append(data[name][random.randint(0, n)])\r\n",
    "\r\n",
    "coo_matrix=[]\r\n",
    "for name in class_names:\r\n",
    "    n=len(data[name])\r\n",
    "    coo_matrix.append({name:n})\r\n",
    "\r\n",
    "print('after')\r\n",
    "print(coo_matrix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "before\n",
      "[{'EMCI': 204}, {'LMCI': 61}, {'MCI': 196}, {'AD': 145}, {'CN': 486}]\n",
      "486\n",
      "after\n",
      "[{'EMCI': 486}, {'LMCI': 486}, {'MCI': 486}, {'AD': 486}, {'CN': 486}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# trainData=[]\r\n",
    "# trainDataLables=[]\r\n",
    "\r\n",
    "# for name in class_names:\r\n",
    "#     for i in data[name]:\r\n",
    "#         trainData.append(i)\r\n",
    "#         for i in range(len(class_names)):\r\n",
    "#             if name==class_names[i]:\r\n",
    "#                 trainDataLables.append(i)\r\n",
    "\r\n",
    "# trainData=np.array(trainData)\r\n",
    "# trainDataLables=np.asarray(trainDataLables)\r\n",
    "# trainData,trainDataLables=shuffle(trainData,trainDataLables)\r\n",
    "\r\n",
    "trainData=[]\r\n",
    "trainDataLables=[]\r\n",
    "\r\n",
    "for name in class_names:\r\n",
    "    for i in data[name]:\r\n",
    "        trainData.append(i)\r\n",
    "        trainDataLables.append(name)\r\n",
    "\r\n",
    "trainData=np.array(trainData)\r\n",
    "trainDataLables=np.asarray(trainDataLables)\r\n",
    "trainData,trainDataLables=shuffle(trainData,trainDataLables)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "lableId=[]\r\n",
    "for i in range(len(trainDataLables)):\r\n",
    "    for j in range(len(class_names)):\r\n",
    "        if trainDataLables[i]==class_names[j]:\r\n",
    "            lableId.append(j)\r\n",
    "\r\n",
    "trainLables=tf.keras.utils.to_categorical(lableId, num_classes=len(class_names), dtype='float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "x_train,x_valid,y_train,y_valid=train_test_split(trainData, trainLables, test_size=0.2, random_state=42)\r\n",
    "x_valid,x_test,y_valid,y_test=train_test_split(x_valid, y_valid, test_size=0.5, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Data Dimension\r\n",
    "num_input = 256         # MNIST data input (image shape: 28x28)\r\n",
    "timesteps = 256          # Timesteps\r\n",
    "n_classes = len(class_names) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "learning_rate = 0.001 # The optimization initial learning rate\r\n",
    "epochs = 100           # Total number of training epochs\r\n",
    "batch_size = 100      # Training batch size\r\n",
    "display_freq = 100    # Frequency of displaying the training results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "num_hidden_units = 128  # Number of hidden units of the RNN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# weight and bais wrappers\r\n",
    "def weight_variable(shape):\r\n",
    "    \"\"\"\r\n",
    "    Create a weight variable with appropriate initialization\r\n",
    "    :param name: weight name\r\n",
    "    :param shape: weight shape\r\n",
    "    :return: initialized weight variable\r\n",
    "    \"\"\"\r\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\r\n",
    "    return tf.get_variable('W',\r\n",
    "                           dtype=tf.float32,\r\n",
    "                           shape=shape,\r\n",
    "                           initializer=initer)\r\n",
    "\r\n",
    "def bias_variable(shape):\r\n",
    "    \"\"\"\r\n",
    "    Create a bias variable with appropriate initialization\r\n",
    "    :param name: bias variable name\r\n",
    "    :param shape: bias variable shape\r\n",
    "    :return: initialized bias variable\r\n",
    "    \"\"\"\r\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\r\n",
    "    return tf.get_variable('b',\r\n",
    "                           dtype=tf.float32,\r\n",
    "                           initializer=initial)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def RNN(x, weights, biases, timesteps, num_hidden):\r\n",
    "\r\n",
    "    # Prepare data shape to match `rnn` function requirements\r\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\r\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\r\n",
    "\r\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\r\n",
    "    x = tf.unstack(x, timesteps, 1)\r\n",
    "\r\n",
    "    # Define a rnn cell with tensorflow\r\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\r\n",
    "\r\n",
    "    # Get lstm cell output\r\n",
    "    # If no initial_state is provided, dtype must be specified\r\n",
    "    # If no initial cell state is provided, they will be initialized to zero\r\n",
    "    states_series, current_state = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\r\n",
    "\r\n",
    "    # Linear activation, using rnn inner loop last output\r\n",
    "    return tf.matmul(current_state, weights) + biases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#  Placeholders for inputs (x) and outputs(y)\r\n",
    "x = tf.placeholder(tf.float32, shape=[None, timesteps, num_input], name='X')\r\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# create weight matrix initialized randomely from N~(0, 0.01)\r\n",
    "W = weight_variable(shape=[num_hidden_units, n_classes])\r\n",
    "\r\n",
    "# create bias vector initialized as zero\r\n",
    "b = bias_variable(shape=[n_classes])\r\n",
    "\r\n",
    "output_logits = RNN(x, W, b, timesteps, num_hidden_units)\r\n",
    "y_pred = tf.nn.softmax(output_logits)\r\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-bacc3322775e>:11: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-13-bacc3322775e>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\Matrix\\.conda\\envs\\tf-amd\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Matrix\\.conda\\envs\\tf-amd\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Model predictions\r\n",
    "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')\r\n",
    "\r\n",
    "# Define the loss function, optimizer, and accuracy\r\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\r\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\r\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\r\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-5acab5d9b666>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Creating the op for initializing all variables\r\n",
    "init = tf.global_variables_initializer()\r\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def randomize(x, y):\r\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\r\n",
    "    permutation = np.random.permutation(y.shape[0])\r\n",
    "    shuffled_x = x[permutation, :]\r\n",
    "    shuffled_y = y[permutation]\r\n",
    "    return shuffled_x, shuffled_y\r\n",
    "\r\n",
    "def get_next_batch(x, y, start, end):\r\n",
    "    x_batch = x[start:end]\r\n",
    "    y_batch = y[start:end]\r\n",
    "    return x_batch, y_batch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "history=[]\r\n",
    "sess = tf.InteractiveSession()\r\n",
    "sess.run(init)\r\n",
    "global_step = 0\r\n",
    "# Number of training iterations in each epoch\r\n",
    "num_tr_iter = int(len(y_train) / batch_size)\r\n",
    "for epoch in range(epochs):\r\n",
    "    print('Training epoch: {}'.format(epoch + 1))\r\n",
    "    x_train, y_train = randomize(x_train, y_train)\r\n",
    "    for iteration in range(num_tr_iter):\r\n",
    "        global_step += 1\r\n",
    "        start = iteration * batch_size\r\n",
    "        end = (iteration + 1) * batch_size\r\n",
    "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\r\n",
    "        x_batch = x_batch.reshape((batch_size, timesteps, num_input))\r\n",
    "        # Run optimization op (backprop)\r\n",
    "        feed_dict_batch = {x: x_batch, y: y_batch}\r\n",
    "        sess.run(optimizer, feed_dict=feed_dict_batch)\r\n",
    "\r\n",
    "        if iteration % display_freq == 0:\r\n",
    "            # Calculate and display the batch loss and accuracy\r\n",
    "            loss_batch, acc_batch = sess.run([loss, accuracy],\r\n",
    "                                             feed_dict=feed_dict_batch)\r\n",
    "\r\n",
    "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\r\n",
    "                  format(iteration, loss_batch, acc_batch))\r\n",
    "\r\n",
    "    # Run validation after every epoch\r\n",
    "\r\n",
    "    feed_dict_valid = {x: x_valid[:1000].reshape((-1, timesteps, num_input)), y: y_valid[:1000]}\r\n",
    "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\r\n",
    "    print('---------------------------------------------------------')\r\n",
    "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\r\n",
    "          format(epoch + 1, loss_valid, acc_valid))\r\n",
    "    print('---------------------------------------------------------')\r\n",
    "    history.append([acc_batch,acc_valid])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training epoch: 1\n",
      "iter   0:\t Loss=1.58,\tTraining Accuracy=31.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 1, validation loss: 1.56, validation accuracy: 35.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 2\n",
      "iter   0:\t Loss=1.55,\tTraining Accuracy=38.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 2, validation loss: 1.50, validation accuracy: 35.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 3\n",
      "iter   0:\t Loss=1.46,\tTraining Accuracy=42.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 3, validation loss: 1.44, validation accuracy: 38.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 4\n",
      "iter   0:\t Loss=1.37,\tTraining Accuracy=44.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 4, validation loss: 1.38, validation accuracy: 43.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 5\n",
      "iter   0:\t Loss=1.24,\tTraining Accuracy=56.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 5, validation loss: 1.34, validation accuracy: 41.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 6\n",
      "iter   0:\t Loss=1.12,\tTraining Accuracy=58.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 6, validation loss: 1.30, validation accuracy: 49.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 7\n",
      "iter   0:\t Loss=1.13,\tTraining Accuracy=55.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 7, validation loss: 1.23, validation accuracy: 49.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 8\n",
      "iter   0:\t Loss=1.09,\tTraining Accuracy=53.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 8, validation loss: 1.19, validation accuracy: 55.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 9\n",
      "iter   0:\t Loss=0.91,\tTraining Accuracy=64.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 9, validation loss: 1.19, validation accuracy: 50.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 10\n",
      "iter   0:\t Loss=1.05,\tTraining Accuracy=61.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 10, validation loss: 1.14, validation accuracy: 57.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 11\n",
      "iter   0:\t Loss=0.93,\tTraining Accuracy=68.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 11, validation loss: 1.13, validation accuracy: 55.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 12\n",
      "iter   0:\t Loss=0.80,\tTraining Accuracy=71.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 12, validation loss: 1.11, validation accuracy: 58.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 13\n",
      "iter   0:\t Loss=0.79,\tTraining Accuracy=75.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 13, validation loss: 1.07, validation accuracy: 55.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 14\n",
      "iter   0:\t Loss=0.70,\tTraining Accuracy=74.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 14, validation loss: 1.03, validation accuracy: 59.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 15\n",
      "iter   0:\t Loss=0.62,\tTraining Accuracy=86.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 15, validation loss: 1.04, validation accuracy: 55.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 16\n",
      "iter   0:\t Loss=0.75,\tTraining Accuracy=69.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 16, validation loss: 1.02, validation accuracy: 61.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 17\n",
      "iter   0:\t Loss=0.68,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 17, validation loss: 1.06, validation accuracy: 60.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 18\n",
      "iter   0:\t Loss=0.67,\tTraining Accuracy=75.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 18, validation loss: 1.02, validation accuracy: 60.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 19\n",
      "iter   0:\t Loss=0.81,\tTraining Accuracy=64.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 19, validation loss: 1.01, validation accuracy: 62.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 20\n",
      "iter   0:\t Loss=0.64,\tTraining Accuracy=79.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 20, validation loss: 1.01, validation accuracy: 64.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 21\n",
      "iter   0:\t Loss=0.63,\tTraining Accuracy=74.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 21, validation loss: 1.00, validation accuracy: 60.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 22\n",
      "iter   0:\t Loss=0.61,\tTraining Accuracy=75.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 22, validation loss: 1.02, validation accuracy: 63.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 23\n",
      "iter   0:\t Loss=0.58,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 23, validation loss: 1.05, validation accuracy: 62.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 24\n",
      "iter   0:\t Loss=0.57,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 24, validation loss: 1.00, validation accuracy: 60.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 25\n",
      "iter   0:\t Loss=0.64,\tTraining Accuracy=78.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 25, validation loss: 1.01, validation accuracy: 63.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 26\n",
      "iter   0:\t Loss=0.64,\tTraining Accuracy=76.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 26, validation loss: 1.02, validation accuracy: 65.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 27\n",
      "iter   0:\t Loss=0.71,\tTraining Accuracy=74.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 27, validation loss: 1.04, validation accuracy: 61.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 28\n",
      "iter   0:\t Loss=0.75,\tTraining Accuracy=67.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 28, validation loss: 1.04, validation accuracy: 62.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 29\n",
      "iter   0:\t Loss=0.57,\tTraining Accuracy=79.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 29, validation loss: 1.04, validation accuracy: 62.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 30\n",
      "iter   0:\t Loss=0.65,\tTraining Accuracy=76.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 30, validation loss: 1.04, validation accuracy: 63.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 31\n",
      "iter   0:\t Loss=0.54,\tTraining Accuracy=79.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 31, validation loss: 1.00, validation accuracy: 63.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 32\n",
      "iter   0:\t Loss=0.47,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 32, validation loss: 1.00, validation accuracy: 64.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 33\n",
      "iter   0:\t Loss=0.62,\tTraining Accuracy=75.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 33, validation loss: 1.03, validation accuracy: 63.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 34\n",
      "iter   0:\t Loss=0.74,\tTraining Accuracy=68.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 34, validation loss: 0.98, validation accuracy: 62.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 35\n",
      "iter   0:\t Loss=0.54,\tTraining Accuracy=78.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 35, validation loss: 1.07, validation accuracy: 65.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 36\n",
      "iter   0:\t Loss=0.63,\tTraining Accuracy=76.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 36, validation loss: 0.97, validation accuracy: 67.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 37\n",
      "iter   0:\t Loss=0.47,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 37, validation loss: 0.99, validation accuracy: 63.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 38\n",
      "iter   0:\t Loss=0.51,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 38, validation loss: 0.96, validation accuracy: 65.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 39\n",
      "iter   0:\t Loss=0.43,\tTraining Accuracy=89.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 39, validation loss: 1.01, validation accuracy: 65.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 40\n",
      "iter   0:\t Loss=0.48,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 40, validation loss: 0.96, validation accuracy: 67.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 41\n",
      "iter   0:\t Loss=0.51,\tTraining Accuracy=81.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 41, validation loss: 1.00, validation accuracy: 65.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 42\n",
      "iter   0:\t Loss=0.44,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 42, validation loss: 1.04, validation accuracy: 62.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 43\n",
      "iter   0:\t Loss=0.50,\tTraining Accuracy=78.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 43, validation loss: 0.99, validation accuracy: 65.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 44\n",
      "iter   0:\t Loss=0.47,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 44, validation loss: 1.03, validation accuracy: 63.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 45\n",
      "iter   0:\t Loss=0.55,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 45, validation loss: 1.00, validation accuracy: 67.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 46\n",
      "iter   0:\t Loss=0.50,\tTraining Accuracy=85.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 46, validation loss: 1.07, validation accuracy: 63.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 47\n",
      "iter   0:\t Loss=0.60,\tTraining Accuracy=84.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 47, validation loss: 1.12, validation accuracy: 61.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 48\n",
      "iter   0:\t Loss=0.69,\tTraining Accuracy=73.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 48, validation loss: 1.07, validation accuracy: 62.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 49\n",
      "iter   0:\t Loss=0.48,\tTraining Accuracy=85.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 49, validation loss: 1.06, validation accuracy: 61.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 50\n",
      "iter   0:\t Loss=0.48,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 50, validation loss: 0.99, validation accuracy: 65.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 51\n",
      "iter   0:\t Loss=0.53,\tTraining Accuracy=80.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 51, validation loss: 0.95, validation accuracy: 67.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 52\n",
      "iter   0:\t Loss=0.46,\tTraining Accuracy=87.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 52, validation loss: 0.96, validation accuracy: 67.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 53\n",
      "iter   0:\t Loss=0.41,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 53, validation loss: 0.94, validation accuracy: 66.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 54\n",
      "iter   0:\t Loss=0.41,\tTraining Accuracy=85.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 54, validation loss: 0.97, validation accuracy: 65.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 55\n",
      "iter   0:\t Loss=0.50,\tTraining Accuracy=81.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 55, validation loss: 1.00, validation accuracy: 65.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 56\n",
      "iter   0:\t Loss=0.33,\tTraining Accuracy=94.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 56, validation loss: 0.99, validation accuracy: 66.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 57\n",
      "iter   0:\t Loss=0.40,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 57, validation loss: 0.96, validation accuracy: 67.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 58\n",
      "iter   0:\t Loss=0.55,\tTraining Accuracy=78.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 58, validation loss: 0.97, validation accuracy: 67.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 59\n",
      "iter   0:\t Loss=0.52,\tTraining Accuracy=80.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 59, validation loss: 0.94, validation accuracy: 71.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 60\n",
      "iter   0:\t Loss=0.45,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 60, validation loss: 0.94, validation accuracy: 69.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 61\n",
      "iter   0:\t Loss=0.32,\tTraining Accuracy=91.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 61, validation loss: 0.93, validation accuracy: 70.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 62\n",
      "iter   0:\t Loss=0.43,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 62, validation loss: 0.95, validation accuracy: 69.1%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 63\n",
      "iter   0:\t Loss=0.44,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 63, validation loss: 1.01, validation accuracy: 69.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 64\n",
      "iter   0:\t Loss=0.30,\tTraining Accuracy=91.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 64, validation loss: 0.95, validation accuracy: 68.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 65\n",
      "iter   0:\t Loss=0.36,\tTraining Accuracy=85.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 65, validation loss: 0.97, validation accuracy: 67.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 66\n",
      "iter   0:\t Loss=0.50,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 66, validation loss: 0.95, validation accuracy: 68.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 67\n",
      "iter   0:\t Loss=0.37,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 67, validation loss: 0.94, validation accuracy: 68.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 68\n",
      "iter   0:\t Loss=0.36,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 68, validation loss: 0.97, validation accuracy: 66.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 69\n",
      "iter   0:\t Loss=0.43,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 69, validation loss: 0.95, validation accuracy: 72.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 70\n",
      "iter   0:\t Loss=0.41,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 70, validation loss: 0.96, validation accuracy: 67.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 71\n",
      "iter   0:\t Loss=0.33,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 71, validation loss: 0.92, validation accuracy: 70.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 72\n",
      "iter   0:\t Loss=0.35,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 72, validation loss: 0.96, validation accuracy: 69.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 73\n",
      "iter   0:\t Loss=0.32,\tTraining Accuracy=92.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 73, validation loss: 0.92, validation accuracy: 71.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 74\n",
      "iter   0:\t Loss=0.39,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 74, validation loss: 0.90, validation accuracy: 71.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 75\n",
      "iter   0:\t Loss=0.41,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 75, validation loss: 0.94, validation accuracy: 69.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 76\n",
      "iter   0:\t Loss=0.41,\tTraining Accuracy=86.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 76, validation loss: 0.93, validation accuracy: 68.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 77\n",
      "iter   0:\t Loss=0.35,\tTraining Accuracy=86.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 77, validation loss: 0.94, validation accuracy: 71.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 78\n",
      "iter   0:\t Loss=0.31,\tTraining Accuracy=89.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 78, validation loss: 0.92, validation accuracy: 71.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 79\n",
      "iter   0:\t Loss=0.30,\tTraining Accuracy=91.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 79, validation loss: 0.96, validation accuracy: 69.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 80\n",
      "iter   0:\t Loss=0.37,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 80, validation loss: 0.90, validation accuracy: 76.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 81\n",
      "iter   0:\t Loss=0.42,\tTraining Accuracy=87.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 81, validation loss: 0.90, validation accuracy: 70.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 82\n",
      "iter   0:\t Loss=0.31,\tTraining Accuracy=89.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 82, validation loss: 0.97, validation accuracy: 68.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 83\n",
      "iter   0:\t Loss=0.27,\tTraining Accuracy=91.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 83, validation loss: 0.94, validation accuracy: 69.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 84\n",
      "iter   0:\t Loss=0.38,\tTraining Accuracy=86.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 84, validation loss: 0.94, validation accuracy: 70.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 85\n",
      "iter   0:\t Loss=0.35,\tTraining Accuracy=90.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 85, validation loss: 0.89, validation accuracy: 71.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 86\n",
      "iter   0:\t Loss=0.41,\tTraining Accuracy=82.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 86, validation loss: 0.87, validation accuracy: 71.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 87\n",
      "iter   0:\t Loss=0.39,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 87, validation loss: 0.87, validation accuracy: 73.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 88\n",
      "iter   0:\t Loss=0.27,\tTraining Accuracy=91.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 88, validation loss: 0.90, validation accuracy: 72.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 89\n",
      "iter   0:\t Loss=0.36,\tTraining Accuracy=87.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 89, validation loss: 0.89, validation accuracy: 74.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 90\n",
      "iter   0:\t Loss=0.32,\tTraining Accuracy=89.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 90, validation loss: 0.93, validation accuracy: 70.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 91\n",
      "iter   0:\t Loss=0.37,\tTraining Accuracy=86.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 91, validation loss: 0.84, validation accuracy: 72.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 92\n",
      "iter   0:\t Loss=0.31,\tTraining Accuracy=90.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 92, validation loss: 0.88, validation accuracy: 71.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 93\n",
      "iter   0:\t Loss=0.34,\tTraining Accuracy=92.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 93, validation loss: 0.87, validation accuracy: 73.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 94\n",
      "iter   0:\t Loss=0.34,\tTraining Accuracy=87.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 94, validation loss: 0.87, validation accuracy: 72.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 95\n",
      "iter   0:\t Loss=0.33,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 95, validation loss: 1.13, validation accuracy: 71.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 96\n",
      "iter   0:\t Loss=0.28,\tTraining Accuracy=92.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 96, validation loss: 1.20, validation accuracy: 67.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 97\n",
      "iter   0:\t Loss=0.35,\tTraining Accuracy=91.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 97, validation loss: 1.08, validation accuracy: 67.5%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 98\n",
      "iter   0:\t Loss=0.56,\tTraining Accuracy=83.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 98, validation loss: 0.87, validation accuracy: 70.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 99\n",
      "iter   0:\t Loss=0.36,\tTraining Accuracy=88.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 99, validation loss: 0.95, validation accuracy: 67.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 100\n",
      "iter   0:\t Loss=0.44,\tTraining Accuracy=81.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 100, validation loss: 0.85, validation accuracy: 76.1%\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "history=np.array(history).transpose()\r\n",
    "index=0\r\n",
    "for i in range(len(history[1])):\r\n",
    "    if history[1][i]==max(history[1]):\r\n",
    "        index=i\r\n",
    "\r\n",
    "print(\"traing acc:\",history[0][index],\"| validation acc:\",history[1][index])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "traing acc: 0.88 | validation acc: 0.76543206\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "testData=[]\r\n",
    "testDataLables=[]\r\n",
    "for name in class_names:\r\n",
    "    images = [cv2.imread(file,cv2.COLOR_BGR2GRAY) for file in glob.glob(path+\"\\\\test\\\\\"+name+r'\\*.jpg')]\r\n",
    "    for i in images:\r\n",
    "        i=cv2.resize(i,(256, 256))\r\n",
    "        testData.append(np.array(i).reshape((256, 256)))\r\n",
    "        testDataLables.append(name)\r\n",
    "\r\n",
    "\r\n",
    "testData=np.asarray(testData)\r\n",
    "testDataLables=np.asarray(testDataLables)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "testlableId=[]\r\n",
    "for i in range(len(testDataLables)):\r\n",
    "    for j in range(len(class_names)):\r\n",
    "        if testDataLables[i]==class_names[j]:\r\n",
    "            testlableId.append(j)\r\n",
    "\r\n",
    "testLables=tf.keras.utils.to_categorical(testlableId, num_classes=len(class_names), dtype='float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "feed_dict_valid = {x: testData, y: testLables}\r\n",
    "loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\r\n",
    "print(acc_valid)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.30769232\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tf-amd': conda)"
  },
  "interpreter": {
   "hash": "c94e96bb83342a8b97e318fe3610a28face5210a30124b5ebd62cb5df9d4f7d9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}