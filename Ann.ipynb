{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import glob\r\n",
    "import cv2\r\n",
    "from tensorflow.keras import models,layers,Sequential\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import random\r\n",
    "from skimage.filters import gabor_kernel\r\n",
    "from scipy import ndimage as ndi\r\n",
    "from sklearn.utils import shuffle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class_names = [\"EMCI\",\"LMCI\",\"MCI\",\"AD\",\"CN\"]\r\n",
    "class_index=[0,1,2,3,4]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path=r\"G:\\dataset\\Alzheimers-ADNI\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "'''reading the images'''\r\n",
    "data=dict()\r\n",
    "# trainData=[]\r\n",
    "# trainDataLables=[]\r\n",
    "coo_matrix=[]\r\n",
    "for name in class_names:\r\n",
    "    images = [cv2.imread(file,cv2.COLOR_BGR2GRAY) for file in glob.glob(path+\"\\\\train\\\\\"+name+r'\\*.jpg')]\r\n",
    "    coo_matrix.append({name:len(images)})\r\n",
    "    temp=[]\r\n",
    "    for i in images:\r\n",
    "        i=cv2.resize(i,(256, 256))\r\n",
    "        temp.append(np.asarray(i).reshape(256, 256,1))\r\n",
    "    data[name]=temp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "'''balancing imbalanced data'''\r\n",
    "print('before')\r\n",
    "print(coo_matrix)\r\n",
    "max_count=0\r\n",
    "for name in class_names:\r\n",
    "    if len(data[name])>max_count:\r\n",
    "        max_count=len(data[name])\r\n",
    "print(max_count)\r\n",
    "\r\n",
    "for name in class_names:\r\n",
    "    n=len(data[name])\r\n",
    "    for t in range(n,max_count):\r\n",
    "        data[name].append(data[name][random.randint(0, n)])\r\n",
    "\r\n",
    "coo_matrix=[]\r\n",
    "for name in class_names:\r\n",
    "    n=len(data[name])\r\n",
    "    coo_matrix.append({name:n})\r\n",
    "\r\n",
    "print('after')\r\n",
    "print(coo_matrix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "before\n",
      "[{'EMCI': 204}, {'LMCI': 61}, {'MCI': 196}, {'AD': 145}, {'CN': 486}]\n",
      "486\n",
      "after\n",
      "[{'EMCI': 486}, {'LMCI': 486}, {'MCI': 486}, {'AD': 486}, {'CN': 486}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "output_size=len(class_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "trainData=[]\r\n",
    "trainDataLables=[]\r\n",
    "\r\n",
    "for name in class_names:\r\n",
    "    for i in data[name]:\r\n",
    "        trainData.append(i.flatten())\r\n",
    "        trainDataLables.append(name)\r\n",
    "\r\n",
    "trainData=np.array(trainData)\r\n",
    "trainDataLables=np.asarray(trainDataLables)\r\n",
    "trainData,trainDataLables=shuffle(trainData,trainDataLables)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "lableId=[]\r\n",
    "for i in range(len(trainDataLables)):\r\n",
    "    for j in range(len(class_names)):\r\n",
    "        if trainDataLables[i]==class_names[j]:\r\n",
    "            lableId.append(j)\r\n",
    "\r\n",
    "trainLables=tf.keras.utils.to_categorical(lableId, num_classes=len(class_names), dtype='float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainData,\r\n",
    "                                                    trainLables,\r\n",
    "                                                    test_size=.25,\r\n",
    "                                                    random_state=1234123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\r\n",
    "                                                    y_test,\r\n",
    "                                                    test_size=.5,\r\n",
    "                                                    random_state=1234123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def dense_block(units, dropout_rate):\r\n",
    "    block = Sequential([\r\n",
    "        layers.Dense(units, activation='relu'),\r\n",
    "        layers.BatchNormalization(),\r\n",
    "        layers.Dropout(dropout_rate)\r\n",
    "    ])\r\n",
    "    \r\n",
    "    return block"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = models.Sequential([\r\n",
    "    layers.Dense(4096, activation='relu',input_shape =(65536,)),\r\n",
    "    layers.Dense(2048, activation='relu'),\r\n",
    "    layers.Dense(1024, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(.3),\r\n",
    "    layers.Dense(512, activation='relu'),\r\n",
    "    layers.Dense(256, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(.2),\r\n",
    "    layers.Dense(128, activation='relu'),\r\n",
    "    layers.Dense(64, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(.2),\r\n",
    "    layers.Dense(32, activation='relu'),\r\n",
    "    layers.Dense(16, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(.2),\r\n",
    "    layers.Dense(output_size, activation='softmax')\r\n",
    "])\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Matrix\\.conda\\envs\\tf-amd\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4096)              268439552 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 279,633,797\n",
      "Trainable params: 279,631,077\n",
      "Non-trainable params: 2,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "METRICS = [tf.keras.metrics.AUC(name='auc')]\r\n",
    "model.compile(\r\n",
    "        optimizer='adam',\r\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\r\n",
    "        metrics=METRICS\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def exponential_decay(lr0, s):\r\n",
    "    def exponential_decay_fn(epoch):\r\n",
    "        return lr0 * 0.1 **(epoch / s)\r\n",
    "    return exponential_decay_fn\r\n",
    "\r\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\r\n",
    "\r\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\r\n",
    "\r\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\r\n",
    "                                                    save_best_only=True)\r\n",
    "\r\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\r\n",
    "                                                     restore_best_weights=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "EPOCHS=100\r\n",
    "history = model.fit(\r\n",
    "    X_train,y_train,\r\n",
    "    validation_data=(X_val,y_val),\r\n",
    "    epochs=EPOCHS,verbose=2\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 1822 samples, validate on 304 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (c:\\Users\\Matrix\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1236758218\\out\\client\\extension.js:90:327199)",
      "at w.execute (c:\\Users\\Matrix\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1236758218\\out\\client\\extension.js:90:326520)",
      "at w.start (c:\\Users\\Matrix\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1236758218\\out\\client\\extension.js:90:322336)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Matrix\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1236758218\\out\\client\\extension.js:90:336863)",
      "at async t.CellExecutionQueue.start (c:\\Users\\Matrix\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1236758218\\out\\client\\extension.js:90:336403)"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tf-amd': conda)"
  },
  "interpreter": {
   "hash": "c94e96bb83342a8b97e318fe3610a28face5210a30124b5ebd62cb5df9d4f7d9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}